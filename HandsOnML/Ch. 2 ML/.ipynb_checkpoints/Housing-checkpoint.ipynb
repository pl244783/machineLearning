{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182ce527",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value ocean_proximity  \n",
      "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
      "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
      "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
      "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
      "4       565.0       259.0         3.8462            342200.0        NEAR BAY   \n",
      "\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n",
      "None \n",
      "\n",
      "\n",
      "\n",
      "<1H OCEAN     9136\n",
      "INLAND        6551\n",
      "NEAR OCEAN    2658\n",
      "NEAR BAY      2290\n",
      "ISLAND           5\n",
      "Name: ocean_proximity, dtype: int64 \n",
      "\n",
      "\n",
      "\n",
      "          longitude      latitude  housing_median_age   total_rooms  \\\n",
      "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
      "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
      "std        2.003532      2.135952           12.585558   2181.615252   \n",
      "min     -124.350000     32.540000            1.000000      2.000000   \n",
      "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
      "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
      "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
      "max     -114.310000     41.950000           52.000000  39320.000000   \n",
      "\n",
      "       total_bedrooms    population    households  median_income  \\\n",
      "count    20433.000000  20640.000000  20640.000000   20640.000000   \n",
      "mean       537.870553   1425.476744    499.539680       3.870671   \n",
      "std        421.385070   1132.462122    382.329753       1.899822   \n",
      "min          1.000000      3.000000      1.000000       0.499900   \n",
      "25%        296.000000    787.000000    280.000000       2.563400   \n",
      "50%        435.000000   1166.000000    409.000000       3.534800   \n",
      "75%        647.000000   1725.000000    605.000000       4.743250   \n",
      "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
      "\n",
      "       median_house_value  \n",
      "count        20640.000000  \n",
      "mean        206855.816909  \n",
      "std         115395.615874  \n",
      "min          14999.000000  \n",
      "25%         119600.000000  \n",
      "50%         179700.000000  \n",
      "75%         264725.000000  \n",
      "max         500001.000000   \n",
      "\n",
      "\n",
      "\n",
      "This is the Train Set: 16512 \n",
      "And this is the Test Set: 4128 \n",
      "\n",
      "\n",
      "Output:\n",
      "3    0.350533\n",
      "2    0.318798\n",
      "4    0.176357\n",
      "5    0.114341\n",
      "1    0.039971\n",
      "Name: income_cat, dtype: float64\n",
      "\n",
      "\n",
      "Correlations:\n",
      "median_house_value    1.000000\n",
      "median_income         0.687151\n",
      "total_rooms           0.135140\n",
      "housing_median_age    0.114146\n",
      "households            0.064590\n",
      "total_bedrooms        0.047781\n",
      "population           -0.026882\n",
      "longitude            -0.047466\n",
      "latitude             -0.142673\n",
      "Name: median_house_value, dtype: float64\n",
      "\n",
      "\n",
      "Values: [-118.51      34.26      29.      2119.       433.      1164.\n",
      "  408.         3.54155] \n",
      "\n",
      "\n",
      "      ocean_proximity\n",
      "12655          INLAND\n",
      "15502      NEAR OCEAN\n",
      "2908           INLAND\n",
      "14053      NEAR OCEAN\n",
      "20496       <1H OCEAN\n",
      "1481         NEAR BAY\n",
      "18125       <1H OCEAN\n",
      "5830        <1H OCEAN\n",
      "17989       <1H OCEAN\n",
      "4861        <1H OCEAN \n",
      "\n",
      "\n",
      "Values converted to Numbers:\n",
      "[[1.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n",
      "\n",
      "Values: [array(['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],\n",
      "      dtype=object)] \n",
      "\n",
      "\n",
      "Value:   (0, 1)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (2, 1)\t1.0\n",
      "  (3, 4)\t1.0\n",
      "  (4, 0)\t1.0\n",
      "  (5, 3)\t1.0\n",
      "  (6, 0)\t1.0\n",
      "  (7, 0)\t1.0\n",
      "  (8, 0)\t1.0\n",
      "  (9, 0)\t1.0\n",
      "  (10, 1)\t1.0\n",
      "  (11, 0)\t1.0\n",
      "  (12, 1)\t1.0\n",
      "  (13, 1)\t1.0\n",
      "  (14, 4)\t1.0\n",
      "  (15, 0)\t1.0\n",
      "  (16, 0)\t1.0\n",
      "  (17, 0)\t1.0\n",
      "  (18, 3)\t1.0\n",
      "  (19, 0)\t1.0\n",
      "  (20, 1)\t1.0\n",
      "  (21, 3)\t1.0\n",
      "  (22, 1)\t1.0\n",
      "  (23, 0)\t1.0\n",
      "  (24, 1)\t1.0\n",
      "  :\t:\n",
      "  (16487, 1)\t1.0\n",
      "  (16488, 0)\t1.0\n",
      "  (16489, 4)\t1.0\n",
      "  (16490, 4)\t1.0\n",
      "  (16491, 1)\t1.0\n",
      "  (16492, 1)\t1.0\n",
      "  (16493, 0)\t1.0\n",
      "  (16494, 0)\t1.0\n",
      "  (16495, 0)\t1.0\n",
      "  (16496, 1)\t1.0\n",
      "  (16497, 0)\t1.0\n",
      "  (16498, 4)\t1.0\n",
      "  (16499, 0)\t1.0\n",
      "  (16500, 0)\t1.0\n",
      "  (16501, 1)\t1.0\n",
      "  (16502, 1)\t1.0\n",
      "  (16503, 1)\t1.0\n",
      "  (16504, 1)\t1.0\n",
      "  (16505, 0)\t1.0\n",
      "  (16506, 0)\t1.0\n",
      "  (16507, 0)\t1.0\n",
      "  (16508, 1)\t1.0\n",
      "  (16509, 0)\t1.0\n",
      "  (16510, 0)\t1.0\n",
      "  (16511, 1)\t1.0 \n",
      "\n",
      "\n",
      "1 Hot Vectors: [[0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]] \n",
      "\n",
      "\n",
      "Listed Categories: [array(['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],\n",
      "      dtype=object)] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CH 2 O'Reilly\n",
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "import numpy as np\n",
    "\n",
    "#downloading data and creating graphs\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "\n",
    "import pandas as pd\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    fetch_housing_data()\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "housing = load_housing_data()\n",
    "print(housing.head(), '\\n\\n\\n')\n",
    "print(housing.info(), '\\n\\n\\n')\n",
    "print(housing[\"ocean_proximity\"].value_counts(), '\\n\\n\\n')\n",
    "print(housing.describe(), '\\n\\n\\n')\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "\n",
    "# graphing out our data\n",
    "# jupyter notebook only\n",
    "# %matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "# housing.hist(bins=50, figsize=(20, 15))\n",
    "# plt.show\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "\n",
    "#splitting and creating a test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
    "print('This is the Train Set:', len(train_set), '\\nAnd this is the Test Set:', len(test_set), '\\n\\n')\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------\n",
    "\n",
    "#graphing income on a bell curve and stratified sampling\n",
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"], \n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf], labels=[1, 2, 3, 4, 5])\n",
    "# housing[\"income_cat\"].hist()\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "    \n",
    "print(\"Output:\\n\", strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set), \"\\n\\n\", sep = \"\")\n",
    "\n",
    "#removal of income_cat so data is back to original state\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)\n",
    "\n",
    "housing = strat_train_set.copy()\n",
    "\n",
    "#visualising the slightly more based way, shows density (lazy c:)\n",
    "# housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)\n",
    "\n",
    "#an even better way of visualizing with colours if you have the energy to actually do it \n",
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4, s=housing[\"population\"]/100, \n",
    "             label=\"population\", figsize=(10, 7), c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"),\n",
    "            colorbar=True)\n",
    "plt.legend()\n",
    "\n",
    "#------------------------------------------------------------------------------------------------\n",
    "\n",
    "#looking for correlations idk, slap in numeric only to get rid of an annoying deprecated warning\n",
    "corr_matrix = housing.corr(numeric_only=True)\n",
    "print(\"Correlations:\\n\", corr_matrix[\"median_house_value\"].sort_values(ascending=False), \"\\n\\n\", sep ='')\n",
    "\n",
    "#plotting the numerical attributes correlated with median housing\n",
    "from pandas.plotting import scatter_matrix\n",
    "# attributes = [\"median_house_value\", \"median_income\", \"total_rooms\", \"housing_median_age\"]\n",
    "# scatter_matrix(housing[attributes], figsize=(12,8))\n",
    "\n",
    "#zoom into specifically into 1 plot\n",
    "# housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\", alpha=0.1)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------\n",
    "\n",
    "#new set, preparing data for ML\n",
    "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "housing.drop(\"total_bedrooms\", axis=1)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy = \"median\")\n",
    "\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "imputer.fit(housing_num)\n",
    "imputer.statistics_\n",
    "print(\"Values:\", housing_num.median().values, \"\\n\\n\")\n",
    "\n",
    "X = imputer.transform(housing_num)\n",
    "housing_tr = pd.DataFrame(X, columns=housing_num.columns, index=housing_num.index)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "#random values idk\n",
    "housing_cat = housing[[\"ocean_proximity\"]]\n",
    "print(housing_cat.head(10), \"\\n\\n\") #displays the first 10 stuff\n",
    "#converting to numbers for ML to work with\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "print(\"Values converted to Numbers:\\n\", housing_cat_encoded[:10], \"\\n\\n\", sep = \"\")\n",
    "print(\"Values:\", ordinal_encoder.categories_, \"\\n\\n\")\n",
    "\n",
    "#categorial values to one-hot vectors\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "print(\"Value:\", housing_cat_1hot, \"\\n\\n\")\n",
    "print(\"1 Hot Vectors:\", housing_cat_1hot.toarray(), \"\\n\\n\")\n",
    "print(\"Listed Categories:\", cat_encoder.categories_, \"\\n\\n\") #same as ordinal_encoder.categories_\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "\n",
    "#custom transformer that fits transforms and fit transforms\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3,4,5,6\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room=True): #no args or kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        else: \n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room = False)\n",
    "housing_extra_attribs = attr_adder.transform(housing.values)\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "\n",
    "#pipeline time yippe\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                        ('attribs_adder', CombinedAttributesAdder()),\n",
    "                        ('std_scaler', StandardScaler())])\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
    "\n",
    "#idk\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([(\"num\", num_pipeline, num_attribs), \n",
    "                                  (\"cat\", OneHotEncoder(), cat_attribs)])\n",
    "housing_prepared = full_pipeline.fit_transform(housing)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "\n",
    "#selecting and training a model \n",
    "from sklearn.linear_model import LinearRegression\n",
    "# lin_reg = LinearRegression()\n",
    "# lin_reg.fit(housing_prepared, housing_labels)\n",
    "# some_data = housing.iloc[:5]\n",
    "# some_labels = housing_labels.iloc[:5]\n",
    "# some_data_prepared = full_pipeline.transform(some_data)\n",
    "# print(\"Predictions:\", lin_reg.predict(some_data_prepared), \"\\n\\n\")\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# housing_predictions = lin_reg.predict(housing_prepared)\n",
    "# lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "# lin_rmse = np.sqrt(lin_mse)\n",
    "# print(\"Mean Squared Error (RMSE):\", lin_rmse, \"\\n\\n\")\n",
    "\n",
    "#--------------------------------------------------------------------------------------------\n",
    "\n",
    "#decision tree regressor\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# tree_reg = DecisionTreeRegressor()\n",
    "# tree_reg.fit(housing_prepared, housing_labels)\n",
    "\n",
    "# #cross validation\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# scores = cross_val_score(tree_reg, housing_prepared, housing_labels, \n",
    "#                          scoring=\"neg_mean_squared_error\", cv=10)\n",
    "# tree_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "# def display_scores(scores):\n",
    "#     print(\"Scores:\", scores)\n",
    "#     print(\"Mean:\", scores.mean())\n",
    "#     print(\"Standard Deviation\", scores.std(), \"\\n\\n\")\n",
    "    \n",
    "# lin_scores = cross_val_score(tree_reg, housing_prepared, housing_labels, \n",
    "#                          scoring=\"neg_mean_squared_error\", cv=10)\n",
    "# lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "# display_scores(lin_rmse_scores)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------\n",
    "\n",
    "#Esemble Learning Model\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# forest_reg = RandomForestRegressor()\n",
    "# forest_reg.fit(housing_prepared, housing_labels)\n",
    "# forest_predictions = forest_reg.predict(housing_prepared)\n",
    "# forest_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "# forest_rmse = np.sqrt(forest_mse) #something is wrong here, and I'm too lazy to fix it, so i'll just mark it\n",
    "# print(\"Forest Value:\", forest_rmse, \"\\n\\n\")\n",
    "# display_scores(forest_rmse_scores)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------\n",
    "\n",
    "# #grid search, experimentation\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_grid = [{'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]}, \n",
    "#                {'bootstrap': [False], 'n_estimators': [3, 10],\n",
    "#               'max_features': [2, 3,4]}]\n",
    "# forest_reg = RandomForestRegressor()\n",
    "# grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring = 'neg_mean_squared_error',\n",
    "#                           return_train_score=True)\n",
    "\n",
    "# grid_search.fit(housing_prepared, housing_labels)\n",
    "# print('Grid Search:', grid_search.best_params_, \"\\n\\n\")\n",
    "# print('Best Estimator:', grid_search.best_estimator_, '\\n\\n')\n",
    "# #if grid search is initialized with refit = True, it'll retrain the whole training set, which is generally pretty poggers and based\n",
    "\n",
    "# cvres = grid_search.cv_results_\n",
    "# for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "#     print(np.sqrt(-mean_score), params)\n",
    "    \n",
    "#----------------------------------------------------------------------------------\n",
    "    \n",
    "#randomized search for large hyperparameters\n",
    "#ensemble good group method idk\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "# from sklearn.svm import SVC\n",
    "# svcReg = SVC(kernel=\"linear\", gamma=0.5, C=1.0)\n",
    "# svcReg.fit(housing_prepared, housing_labels)\n",
    "# svcPredictions = svcReg.predict(housing_prepared)\n",
    "# print('hi')\n",
    "# gridSearch = GridSearchCV(svcReg, param_grid, cv=5, scoring = 'neg_mean_squared_error',\n",
    "#                            return_train_score=True)\n",
    "# gridSearch.fit(housing_prepared, housing_labels)\n",
    "# print('Grid Search:', grid_search.best_params_, \"\\n\\n\")\n",
    "# print('Best Estimator:', grid_search.best_estimator_, '\\n\\n')\n",
    "# #RMSE\n",
    "# housingPredictions = svcReg.predict(housing_prepared)\n",
    "# svcMse= mean_squared_error(housing_labels, housingPredictions)\n",
    "# svcRmse = np.sqrt(svcMse)\n",
    "# print(\"Mean Squared Error (RMSE):\", svcRmse, \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ba9cee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
